{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b5431a-6c15-45c1-a8a7-c991d297ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "# from dotenv import load_dotenv\n",
    "import time\n",
    "import re\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# path = '/content/gdrive/My Drive/585data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35517455-2383-40f7-8388-6b836f07bf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"groundTruth\": [\"现身说法\"], \"candidates\": [[\"旷日持久\", \"公正廉洁\", \"苦口婆心\", \"现身说法\", \"白日做梦\", \"深入浅出\", \"肺腑之言\"]], \"content\": \"只要路过的旅客稍有迟疑，或者对他们的宣传单多看几眼，基本上这个旅客就别想轻松脱身了，记者就在9月3日接站时目睹了这样一幕：一个学生接过招生人员递来的宣传单，只是问了一下“你们学校有没有分数要求？”两个招生人员就“白话”开了，一个表示分数都好说，只要有好学的精神；另一个则#idiom#，大讲自己选择的专业现在收获颇丰；最后在招生人员“我们学校毕业后可以完全解决就业”的忽悠下，这个学生旅客被他们拉上了到校参观的班车。\", \"realCount\": 1}\\n', '{\"groundTruth\": [\"神来之笔\", \"赞不绝口\"], \"candidates\": [[\"画龙点睛\", \"悔过自新\", \"拍案叫绝\", \"鬼斧神工\", \"神来之笔\", \"颠倒黑白\", \"中流砥柱\"], [\"敬谢不敏\", \"拍案叫绝\", \"心悦诚服\", \"叹为观止\", \"赞不绝口\", \"口口声声\", \"扬眉吐气\"]], \"content\": \"亨利的这个#idiom#被法国媒体形容为“空中舞蹈”，亨利自己对球队表现也很满意，“上半场开局一般，但很快觉醒，下半场的进攻让人看到真正的法国，尤其是我们的速度让对方有了麻烦。”而和亨利搭档的本泽马对老大哥#idiom#，“和他在一起配合很容易，他给了我很多信心。”\", \"realCount\": 2}\\n'] \n",
      " 3000\n"
     ]
    }
   ],
   "source": [
    "# path = '../data/'    # change the path as needed\n",
    "path = '../' #'/content/gdrive/My Drive/585data/'\n",
    "\n",
    "def read_data(file):\n",
    "    with open (path+file) as t:\n",
    "        data = t.readlines()\n",
    "    return data\n",
    "\n",
    "# ChatGPT API only allow 3 prompts per minute, so we cannot make 3000 as other models here.\n",
    "test_set = read_data('test_data.txt')[:3000]\n",
    "\n",
    "# type(train_set)\n",
    "print(test_set[:2], '\\n', len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f48fcd4-f8a0-4313-b2b3-0284213fb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "api_path = path + 'openai_gpt_api_key.txt'\n",
    "\n",
    "### read api key from file\n",
    "with open(api_path, \"r\") as file:\n",
    "    API_KEY = file.read().strip()\n",
    "\n",
    "openai.api_key = API_KEY\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "messages = []\n",
    "\n",
    "def ask_gpt(input_text, print_results = True, delay: float = 1):\n",
    "    \"\"\"\n",
    "    API call to gpt-3.5-turbo. Note: each time the function is called, the API call will keep previous calls to the model as context until the kernel is restarted.\n",
    "    If you would like to reset the model's conversational context, restart kernel and run the function again.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    `input`: str\n",
    "        user input that is passed to model. Used in the same way information is passed to the model in the OpenAI web interface for ChatGPT\n",
    "    `print_results`: bool = True\n",
    "        if model's returned text exceeds a certain number of characters, it includes new line marking \"\\n\". if print_result == True,\n",
    "        function splits printout by \"\\n\" and print results out line by line, otherwise results are only returned as a list object,\n",
    "        with each list item as a line of the printout\n",
    "    `delay`: float\n",
    "        amount by which to delay sequential API calls (calls in sequence that are too frequent can lead to a ban in certain instances - this avoids that)\n",
    "    \n",
    "    Returns:\n",
    "    ------\n",
    "    `result_list`: list\n",
    "        only returned if `print_result` == False. Return is a list object with returned text from the model split by \"\\n\".\n",
    "        If returned text is short enough and no text is present, list will only be length of 1\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    time.sleep(delay)\n",
    "    \n",
    "    # global messages\n",
    "    messages.append({\"role\": \"user\", \"content\": input_text})\n",
    "    chat_test = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 0.1,\n",
    "        messages = messages)\n",
    "    \n",
    "    result_list = chat_test.choices[0].message.content#.split(\"\\n\") # if not split, the returned text is more than one line, the printout has \"\\n\" in it\n",
    "\n",
    "    # if print_results == True:\n",
    "    #     for line in result_list:\n",
    "    #         print (line)\n",
    "    # else:\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9529c8-7854-478e-beea-713f4476b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(data):\n",
    "    '''data shall be the output of `read_data`'''\n",
    "    text_input = []\n",
    "    gold = []\n",
    "    for i in range(len(data)):\n",
    "        data[i] = eval(data[i])\n",
    "        input_text = data[i]['content']\n",
    "        candidates = data[i]['candidates']\n",
    "        ground_truth = set(data[i]['groundTruth'])\n",
    "        gold.append(ground_truth)\n",
    "\n",
    "        candidate_str = ''\n",
    "        for candidate in candidates:\n",
    "            candidate_str += '('+'|'.join(candidate)+')'\n",
    "        \n",
    "        # preprocess_idx = -1\n",
    "        # def replace(match):\n",
    "        #     nonlocal preprocess_idx\n",
    "        #     preprocess_idx += 1\n",
    "        #     return 'extra{}'.format(preprocess_idx)\n",
    "        # input_text = re.sub(r'#idiom#', replace, input_text)\n",
    "\n",
    "        instruction = f'''示例1：(意气风发|街谈巷议|人才辈出|一脉相传|后继有人|发扬光大|腥风血雨)(平易近人|落落大方|八仙过海|彬彬有礼|史无前例|盛气凌人|好自为之)(不拘小节|风流潇洒|无病呻吟|言谈举止|壮志凌云|关门闭户|温文尔雅)\n",
    "历史上的蒋南翔是著名的“一二九”学生救亡运动的领导人之一，他在清华校长之位14年期间，不但很好的继承了清华建校之初的优秀传统与理念，而且更加的#idiom#，他把清华的教师队伍扩大了将近5倍，将清华本科人数破万，为新中国培养了大量的有用人才。在《天行健》中饰演蒋南翔的刘威是观众所熟悉的著名实力派演员，早在1987年刘威就在《关东大侠》中饰演豪爽仗义的关云天一角而获得了金鸡奖最佳男主角的提名，后来更是因在《唐明皇》中精湛的表演而一举夺得金鹰奖最佳男演员奖。此次《天行健》选定刘威来出演正是看中了他#idiom#的表演方式和对人物深入内心的刻画。至此，《天行健》中涉及的三位清华校长的人选都已经曝光，#idiom#的第一任校长赵文?、稳重坚毅的第二任校长孙逊、亲切务实的第三任校长刘威，再加上梁思成、林徽因、朱自清、闻一多等一批“大师”的加盟，相信作为清华百年校庆重点项目之一的《天行健》一定会带领观众重温那段不能抹去的历史。 \n",
    "示例1的正确答案为：发扬光大,平易近人,温文尔雅\n",
    "示例2：(深恶痛绝|人人自危|恨入骨髓|不胜枚举|嗤之以鼻|走马看花|不屑一顾)\n",
    "另据了解，北京一个对垃圾短信#idiom#的老人，利用该软件总共呼死了近2000个号码。20分钟呼上万号码记者昨天在百度里输入“呼死你软件”，出现了7000多个相关网页，随机登录几个网站，发现软件均需花钱购买，价格从200元至500元不等。 \n",
    "示例2的正确答案为：深恶痛绝\n",
    "请按照上述示例，从下列括号中分别选择合适的成语填入\"#idiom#\"处，请仅回复成语，不要回复其他字符：{candidate_str}'''\n",
    "        \n",
    "        text_input.append(instruction+'\\n'+input_text)\n",
    "\n",
    "    return text_input, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370875c9-5c27-4cfd-8e37-58a8eb61ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, gold = prompt(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665e27b3-c98b-4723-8374-b3ed5b3a604b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'示例1：(意气风发|街谈巷议|人才辈出|一脉相传|后继有人|发扬光大|腥风血雨)(平易近人|落落大方|八仙过海|彬彬有礼|史无前例|盛气凌人|好自为之)(不拘小节|风流潇洒|无病呻吟|言谈举止|壮志凌云|关门闭户|温文尔雅)\\n历史上的蒋南翔是著名的“一二九”学生救亡运动的领导人之一，他在清华校长之位14年期间，不但很好的继承了清华建校之初的优秀传统与理念，而且更加的#idiom#，他把清华的教师队伍扩大了将近5倍，将清华本科人数破万，为新中国培养了大量的有用人才。在《天行健》中饰演蒋南翔的刘威是观众所熟悉的著名实力派演员，早在1987年刘威就在《关东大侠》中饰演豪爽仗义的关云天一角而获得了金鸡奖最佳男主角的提名，后来更是因在《唐明皇》中精湛的表演而一举夺得金鹰奖最佳男演员奖。此次《天行健》选定刘威来出演正是看中了他#idiom#的表演方式和对人物深入内心的刻画。至此，《天行健》中涉及的三位清华校长的人选都已经曝光，#idiom#的第一任校长赵文?、稳重坚毅的第二任校长孙逊、亲切务实的第三任校长刘威，再加上梁思成、林徽因、朱自清、闻一多等一批“大师”的加盟，相信作为清华百年校庆重点项目之一的《天行健》一定会带领观众重温那段不能抹去的历史。 \\n示例1的正确答案为：发扬光大,平易近人,温文尔雅\\n示例2：(深恶痛绝|人人自危|恨入骨髓|不胜枚举|嗤之以鼻|走马看花|不屑一顾)\\n另据了解，北京一个对垃圾短信#idiom#的老人，利用该软件总共呼死了近2000个号码。20分钟呼上万号码记者昨天在百度里输入“呼死你软件”，出现了7000多个相关网页，随机登录几个网站，发现软件均需花钱购买，价格从200元至500元不等。 \\n示例2的正确答案为：深恶痛绝\\n请按照上述示例，从下列括号中分别选择合适的成语填入\"#idiom#\"处，请仅回复成语，不要回复其他字符：(画龙点睛|悔过自新|拍案叫绝|鬼斧神工|神来之笔|颠倒黑白|中流砥柱)(敬谢不敏|拍案叫绝|心悦诚服|叹为观止|赞不绝口|口口声声|扬眉吐气)\\n亨利的这个#idiom#被法国媒体形容为“空中舞蹈”，亨利自己对球队表现也很满意，“上半场开局一般，但很快觉醒，下半场的进攻让人看到真正的法国，尤其是我们的速度让对方有了麻烦。”而和亨利搭档的本泽马对老大哥#idiom#，“和他在一起配合很容易，他给了我很多信心。”'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e753e64d-da47-4aa9-a67a-701730d6a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'现身说法'}, {'神来之笔', '赞不绝口'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c963b6-1a2a-4f16-ae62-618a2845de17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'神来之笔，拍案叫绝'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt(test_input[1], delay = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4b37eb-838a-45e7-ab2b-dc89e8ad5990",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e042be6145339bcfc91680c4443d6bc in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m test_input:\n\u001b[0;32m----> 3\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mask_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 。，答案：#\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mset\u001b[39m(a))\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mask_gpt\u001b[0;34m(input_text, print_results, delay)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# global messages\u001b[39;00m\n\u001b[1;32m     41\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_text})\n\u001b[0;32m---> 42\u001b[0m chat_test \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m result_list \u001b[38;5;241m=\u001b[39m chat_test\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;66;03m#.split(\"\\n\") # if not split, the returned text is more than one line, the printout has \"\\n\" in it\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# if print_results == True:\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     for line in result_list:\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#         print (line)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e042be6145339bcfc91680c4443d6bc in your message.)"
     ]
    }
   ],
   "source": [
    "sys = []\n",
    "for q in test_input:\n",
    "    a = ask_gpt(q, delay=0.1)\n",
    "    a = a.strip(' 。，答案：#').split(',')\n",
    "    sys.append(set(a))\n",
    "### The fee was used up so this is interrupted... \n",
    "### It took around 2 hours so we decided not to continue TAT\n",
    "### We have run 2096 test data for now (2096/3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437d5345-77d2-4289-936c-fa5042a12fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2449970d-9e23-483e-afed-b28a31d799f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatgpt_ans.txt', 'w') as a:\n",
    "    for s in sys:\n",
    "        a.write(str(s)+'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012cec52-3b06-44ed-8aee-012f36a9150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(sys, gold):\n",
    "    tp = 0\n",
    "    total = 0\n",
    "    pos = 0\n",
    "    for s, g in zip(sys, gold):\n",
    "        total += len(g)\n",
    "        pos += len(s)\n",
    "        tp += len(g & s)\n",
    "    precision = tp / pos if pos != 0 else 0\n",
    "    recall = tp / total if total != 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    return precision, recall, f1, tp\n",
    "\n",
    "def accuracy(sys, gold, tp):\n",
    "    total = 0\n",
    "    for s, g in zip(sys, gold):\n",
    "        total += len(g)\n",
    "    return tp / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a1262a-c1b3-4204-b7fb-5386ef45e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: \n",
      "Accuracy for test set is 0.18822124950258656\n",
      "F1 score for test set is 0.20348462034846204\n"
     ]
    }
   ],
   "source": [
    "p, r, f1, tp = f1_score(sys, gold)\n",
    "print('ChatGPT: ')\n",
    "print(f\"Accuracy for test set is {accuracy(sys, gold, tp)}\")\n",
    "print(f\"F1 score for test set is {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee6b6c5-d15c-468c-a6c3-e21efd8811be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'苦口婆心'} {'现身说法'}\n",
      "{'亨利的这个神来之笔被法国媒体形容为“空中舞蹈”，亨利自己对球队表现也很满意，“上半场开局一般，但很快觉醒，下半场的进攻让人看到真正的法国，尤其是我们的速度让对方有了麻烦。”而和亨利搭档的本泽马对老大哥拍案叫绝，“和他在一起配合很容易，他给了我很多信心。”'} {'神来之笔', '赞不绝口'}\n",
      "{'劳燕分飞'} {'难分难舍'}\n",
      "{'强弩之末'} {'凶多吉少'}\n",
      "{'示例答案：孤注一掷'} {'孤注一掷'}\n",
      "{'墨守成规'} {'闭门造车'}\n",
      "{'恰如其分'} {'锦上添花'}\n",
      "{'目前，进行电子阅读的用户均有手机上网包月套餐，并不担心上网产生额外的流量费，也就是说其阅读的电子书基本是免费资源，这或许可以解释为什么电子阅读发展能够如此迅速。免费对消费者具有足够的吸引力：“零价格已经不仅仅是另一个价格了，它已经成为了一个让情感繁文缛礼的按钮，成为非理性快乐的源泉”。消费者购买再便宜的产品也会害怕吃亏，这种本能极大影响了其购买决策；而对于免费产品则根本不存在吃亏的问题，只有好处的现实会让其感情迅速充电，毫不犹豫地选择免费产品。所以坚持几年之内不赚钱而专心培育市场是开启电子“悦读”时代所必须的'} {'一触即发'}\n",
      "{'分工合作，泰然自若，惊惶失措'} {'全神贯注', '惊惶失措'}\n",
      "{'一般无二'} {'本来面目'}\n",
      "{'字斟句酌'} {'洋洋洒洒'}\n",
      "{'怒火中烧，自力更生'} {'自力更生', '气势汹汹'}\n",
      "{'记者在现场看到，事故现场的沙堆积如山。沙场工作人员黄先生介绍说，当时沙堆又多又高，只要有一点震动，上面大量的沙子就会往下流动，大家都知道很危险，平时都不敢随便靠近的。事发当天上午9点左右，该女老板还问过他沙子质量如何，没想到10点多就发生意外了'} {'堆积如山'}\n",
      "{'骑虎难下'} {'狗急跳墙'}\n",
      "{'瞒天过海'} {'冒名顶替'}\n",
      "{'这种感觉很快便让他恢复了坦然自若的感觉'} {'坦然自若'}\n",
      "{'从政后，两人的成就皆令人刮目相待，爱德华通晓英国内政事务，曾帮助布朗起草政府年度工作草案。在外交舞台上，当过外交大臣的哥哥更有优势，美国国务卿希拉里就直率地表示戴维·米利班德给她留下了很好的印象'} {'刮目相待'}\n",
      "{'力排众议，一成不变'} {'周而复始'}\n",
      "{'这个场面有些滑稽，猛冲猛打人家根本不怕你，彼此争抢也能把你卡在身后，没想到从你胯下夸张的横出一腿，反而让牢固的城池岌岌可危，颇有些“四两拨千斤”的味道。赛后鲁尼这样评价进球：“这是帕特(埃弗拉)的绝妙传球，尽管我能看到球过来了，但我不能看到皮球的全部，因为贝巴跳了起来(干扰了视线)，但我还是把腿伸了出来，感谢上帝我碰到它了。”'} {'土崩瓦解'}\n",
      "{'以退为进'} {'明哲保身'}\n",
      "{'任劳任怨，从容自若'} {'笑容可掬'}\n",
      "{'防不胜防'} {'措手不及'}\n",
      "{'嬉皮笑脸'} {'满面春风'}\n",
      "{'但是这个换人决定非但没能解决场上的问题，还更加暴露了利物浦目前的艰难处境：中场缺少一个冷静的大脑———阿奎拉尼上场后，出球屡屡慢半拍，被对手铲得七零八碎。此前杰拉德打后腰位置虽然遏制了他的进攻能力，但在防守上还是有保障的。意大利中场替补上来后，让搭档卢卡斯人仰马翻。他对于比赛节奏的掌控，并没有在过去两场联赛中改进，一遇到打法粗野的英冠球队愈发示弱'} {'人仰马翻', '疲於奔命'}\n",
      "{'旗鼓相当，稍逊一筹，风吹草动'} {'风吹草动', '旗鼓相当'}\n",
      "{'经年累月，戎马生涯，让人深思的是爱情的力量，它可以#idiom#，也可以#idiom#，让人心魄荡漾，回肠荡气'} {'扣人心弦'}\n",
      "{'自作自受'} {'鸿鹄之志'}\n",
      "{'危在旦夕'} {'奄奄一息'}\n",
      "{'李岚建议报社加入文字著作权协会，由文著协代表权利人维权，避免#idiom'} {'墨守成规'}\n",
      "{'束手束脚'} {'雷打不动'}\n",
      "{'手足无措'} {'绘声绘色'}\n",
      "{'李宗盛好友成龙的儿子房祖名亦是他的得意门生之一。说到师父李宗盛，房祖名佩服得肃然起敬：“师父的压力比父亲来得更重，一想到不能丢师父的脸，我就会努力。”房祖名说，以前没进娱乐圈，不知道很多事情那么复杂，但是李宗盛可以走出娱乐圈做纯粹的音乐，活得很快乐，他也希望能像师父那样，两耳不闻窗外事，好好做音乐'} {'五体投地'}\n",
      "{'安家落户'} {'惊天动地'}\n",
      "{'交相辉映'} {'五颜六色'}\n",
      "{'这与其在资本市场近20年的履历#发扬光大'} {'一脉相传'}\n",
      "{'暴风骤雨'} {'狂轰滥炸'}\n",
      "{'不可一世'} {'彻头彻尾'}\n",
      "{'示例答案：难解难分'} {'平分秋色'}\n",
      "{'前思后想'} {'和盘托出'}\n",
      "{'手疾眼快'} {'不偏不倚'}\n",
      "{'模棱两可'} {'含糊其词'}\n",
      "{'根据美国与伊拉克之间的撤军安排，今年6月底之前，美国已经从伊拉克主要城镇撤走主要战斗力量，退入军营，现在还有12万部队，预计明年8月底将撤走所有战斗人员。在这个过程中，伊拉克军队、伊拉克的警方能否成长起来，能否圆满地担负保家卫国、保国安良这个使命，是伊拉克政府面临的巨大考验，如果处理不好的话，有可能影响美军的撤军计划'} {'保家卫国'}\n",
      "{'旧事重提'} {'借题发挥'}\n",
      "{'落落大方'} {'不足为奇'}\n",
      "{'先礼后兵'} {'以牙还牙'}\n",
      "{'条条框框，正经八百，炉火纯青'} {'正经八百', '畏缩不前', '一嚬一笑'}\n",
      "{'富丽堂皇', '俗不可耐', '盛气凌人'} {'深宅大院', '自高自大'}\n",
      "{'速战速决'} {'扬眉吐气'}\n",
      "{'据了解，警方已经正式表态，一定尽快破案，抓住偷盗者，争取把损失的重要物品物归原主。韩教“光脚”赶路这次盗窃事件中，最惨痛的当然是主教练姜正秀，不光电脑被偷，衣服、鞋子也被毛贼据为己有，以至于他不得不穿着拖鞋赶路'} {'物归原主', '顺手牵羊'}\n",
      "{'亲密无间'} {'推心置腹'}\n",
      "{'如芒在背，不要去那里！”但是玛丽听了反而更加兴奋了，她觉得这才是真正的冒险。于是她毅然决定前往劳格族的部落，不想却遭遇了#idiom#的惨'} {'毛骨悚然', '缚鸡之力'}\n",
      "{'令人发指'} {'触目惊心'}\n",
      "{'融会贯通'} {'登堂入室'}\n",
      "{'全力以赴，争分夺秒'} {'全力以赴'}\n",
      "{'勉为其难，宽宏大量，各行其是'} {'死心塌地', '诚心诚意'}\n",
      "{'从包产到户到#雄心壮志#我喜欢跟一批人干活，不喜欢一个人干。创业初期，环顾周围的老师和工作人员，能够成为我的合作者的几乎没有，看来合作者只能是我大学的同学。我就到美国去了，跟他们聊天，刚开始他们都不愿意回来。当时王强在贝尔实验室工作，年薪8万美金，他一个问题就把我问住了：“老俞，我现在相当于60万人民币，回去了你能给我开60万人民币的工资吗？另外你给我60万，跟在美国赚的钱一样，我值得回去吗？”当时新东方一年的利润也就是一百多万，全给他是不太可能的'} {'雄心壮志'}\n",
      "{'大展宏图，一言一行'} {'一路顺风', '文武全才'}\n",
      "{'耀武扬威'} {'无独有偶'}\n",
      "{'示例答案：恰如其分'} {'恰如其分'}\n",
      "{'明争暗斗'} {'前车之鉴'}\n",
      "{'水滴石穿'} {'理所当然'}\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "for s, g in zip(sys, gold):\n",
    "    if s != g:\n",
    "        print(s, g)\n",
    "        p += 1\n",
    "    if p > 60:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb2d44d2-aba2-4569-8455-24f732a5f0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1e723-1efe-414c-a917-d05a76c4a1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
